{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary -\n",
    "# - There are totally 59K touch gestures.\n",
    "# - Only ~22K (37%) touch gestures was clicked on a leaf element which had text content.\n",
    "# - Created text dataset in the following format\n",
    "#   - [[e11, e21, ... e1(MAX_TOKEN), e21, e22, ... e2(MAX_TOKEN), TARGET_TEXT],\n",
    "#      ...\n",
    "#     ]\n",
    "#   - Vectorized the dataset.\n",
    "# - Tried a simple classification model with a single hidden layer(1024).\n",
    "#   - Accuracy on train data : 48%\n",
    "#   - Accuracy on validation (20%) : 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements.\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants.\n",
    "LONG_TOUCH_THRESHOLD = 5\n",
    "DIM_X = 1440\n",
    "DIM_Y = 2560\n",
    "MAX_TOKEN = 64\n",
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 100\n",
    "VOCAB_SIZE = 100\n",
    "TRAIN_SIZE = 0.8\n",
    "VAL_SIZE = 0.1\n",
    "TEST_SIZE = 0.1\n",
    "TRACES_PATH = 'filtered_traces/*/*'\n",
    "NEGATIVE_SAMPLE_TARGET = '[null]'\n",
    "PLACEHOLDER_TEXT = 'n/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all leaf nodes for a given element.\n",
    "def get_leaf_nodes(element, leaf_nodes):\n",
    "    if not element:\n",
    "        return leaf_nodes\n",
    "    if 'children' not in element:\n",
    "        leaf_nodes.append(element)\n",
    "        return leaf_nodes\n",
    "    for child in element['children']:\n",
    "        get_leaf_nodes(child, leaf_nodes)\n",
    "    return leaf_nodes\n",
    "\n",
    "\n",
    "def get_all_leaf_nodes(view_hierarchy_json):\n",
    "    activity = view_hierarchy_json.get('activity')\n",
    "    if not activity:\n",
    "        return dataset\n",
    "    root = activity.get('root')\n",
    "    return get_leaf_nodes(root, [])\n",
    "\n",
    "\n",
    "def get_target_text(leaf_nodes, x, y):\n",
    "    target_text = None\n",
    "    for leaf_node in leaf_nodes:\n",
    "        bounds = leaf_node['bounds']\n",
    "        if bounds[0] <= x and bounds[2] >= x and bounds[1] <= y and bounds[3] >= y:\n",
    "            if 'text' in leaf_node:\n",
    "                target_text = leaf_node['text'] or leaf_node.get('text-hint')\n",
    "    return target_text\n",
    "\n",
    "\n",
    "def get_leaf_node_features(leaf_nodes):\n",
    "    i = 1\n",
    "    element_features = []\n",
    "    for leaf_node in leaf_nodes:\n",
    "        if 'text' in leaf_node:\n",
    "            text = leaf_node['text'] or leaf_node.get('text-hint')\n",
    "            _class = leaf_node['class']\n",
    "            element_features.append(str(text))\n",
    "            element_features.append(str(_class))\n",
    "            i += 1\n",
    "            if i == MAX_TOKEN:\n",
    "                break\n",
    "    return element_features\n",
    "\n",
    "\n",
    "\n",
    "# Identifies if a given gesture is a TOUCH gesture.\n",
    "# In this task, we will only be focussing on TOUCH gestures.\n",
    "def is_touch_gesture(gesture):\n",
    "    if len(gesture) <= LONG_TOUCH_THRESHOLD:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of touch gestures  59602\n",
      "Number of non-touch gestures  6659\n"
     ]
    }
   ],
   "source": [
    "dirs = glob.glob(TRACES_PATH)\n",
    "touch_gesture_count = 0\n",
    "non_touch_gesture_count = 0\n",
    "for d in dirs:\n",
    "  with open(f'{d}/gestures.json') as f:\n",
    "    gestures = json.load(f)\n",
    "    gestures = [gestures[x] for x in sorted(gestures, key=lambda x: int(x))]\n",
    "    for gesture in gestures:\n",
    "        if is_touch_gesture(gesture):\n",
    "            touch_gesture_count += 1\n",
    "        else:\n",
    "            non_touch_gesture_count += 1\n",
    "print('Number of touch gestures ', touch_gesture_count)\n",
    "print('Number of non-touch gestures ', non_touch_gesture_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processes view hierarchies to construct dataset.\n",
    "# Extract texts from MAX_TOKEN elements from both view hierarchies.\n",
    "# Construct the dataset in the following format -\n",
    "# [[e11, e21, ... e1(MAX_TOKEN), e21, e22, ... e2(MAX_TOKEN), TARGET_TEXT], ...]\n",
    "\n",
    "def get_features(leaf_nodes1, leaf_nodes2):\n",
    "    screen1_features = get_leaf_node_features(leaf_nodes1)\n",
    "    screen2_features = get_leaf_node_features(leaf_nodes2)\n",
    "\n",
    "    for i in range(int(len(screen1_features) / 2), MAX_TOKEN):\n",
    "        screen1_features.append(PLACEHOLDER_TEXT)  # Element Text.\n",
    "        screen1_features.append(PLACEHOLDER_TEXT)  # Element Class.\n",
    "    for i in range(int(len(screen2_features) / 2), MAX_TOKEN):\n",
    "        screen2_features.append(PLACEHOLDER_TEXT)  # Element Text.\n",
    "        screen1_features.append(PLACEHOLDER_TEXT)  # Element Class.\n",
    "    \n",
    "    return screen1_features, screen2_features\n",
    "\n",
    "\n",
    "def process_view_hierarchy(view_hierarchy1, view_hierarchy2, dataset, is_positive_sample = True):\n",
    "    if not view_hierarchy1 or not view_hierarchy2:\n",
    "        return dataset\n",
    "    \n",
    "    trace_path = view_hierarchy1.split('view_hierarchies')[0]\n",
    "    gesture_path = f'{trace_path}/gestures.json'\n",
    "    with open(gesture_path) as file:\n",
    "        gestures = json.load(file)\n",
    "\n",
    "    with open(view_hierarchy1) as file:\n",
    "        view_hierarchy1_json = json.load(file)\n",
    "    with open(view_hierarchy2) as file:\n",
    "        view_hierarchy2_json = json.load(file)\n",
    "    \n",
    "    if not view_hierarchy1_json or not view_hierarchy2_json:\n",
    "        return dataset\n",
    "\n",
    "    ui_number = view_hierarchy1.split('/')[-1].split('.')[0]\n",
    "    gesture = gestures[ui_number]\n",
    "    if not is_touch_gesture(gesture):\n",
    "        return dataset\n",
    "    \n",
    "    if not len(gesture):\n",
    "        return dataset\n",
    "    x_cord = gesture[0][0]\n",
    "    y_cord = gesture[0][1]\n",
    "    x = x_cord * DIM_X\n",
    "    y = y_cord * DIM_Y\n",
    "\n",
    "    leaf_nodes1 = get_all_leaf_nodes(view_hierarchy1_json)\n",
    "    leaf_nodes2 = get_all_leaf_nodes(view_hierarchy2_json)\n",
    "\n",
    "    target_text = get_target_text(leaf_nodes1, x, y)\n",
    "    if not target_text:\n",
    "        return dataset\n",
    "    \n",
    "    screen1_features, screen2_features = get_features(leaf_nodes1, leaf_nodes2)\n",
    "\n",
    "    if is_positive_sample:\n",
    "        dataset.append(screen1_features + screen2_features + [target_text])\n",
    "    else:\n",
    "        dataset.append(screen1_features + screen2_features + [NEGATIVE_SAMPLE_TARGET])\n",
    "    return dataset\n",
    "        \n",
    "\n",
    "def process_trace(trace_path, dataset):\n",
    "    view_hierarchies_path = f'{trace_path}/view_hierarchies/*'\n",
    "    view_hierarchies = sorted(glob.glob(view_hierarchies_path))\n",
    "    for i in range(len(view_hierarchies) - 1):\n",
    "        dataset = process_view_hierarchy(view_hierarchies[i], view_hierarchies[i+1], dataset)\n",
    "\n",
    "\n",
    "def add_negative_samples(dataset):\n",
    "    traces = sorted(glob.glob(TRACES_PATH))\n",
    "    total_positive_samples = len(dataset)\n",
    "    negative_samples_threshold = 0.1 * total_positive_samples\n",
    "    negative_samples_counter = 0\n",
    "    for i in range(len(traces) - 1):\n",
    "        trace_path1 = traces[i]\n",
    "        trace_path2 = traces[i+1]\n",
    "        view_hierarchies1_path = sorted(glob.glob(f'{trace_path1}/view_hierarchies/*'))\n",
    "        view_hierarchies2_path = sorted(glob.glob(f'{trace_path2}/view_hierarchies/*'))\n",
    "        for (view_hierarchy1, view_hierarchy2) in zip(view_hierarchies1_path, view_hierarchies2_path):\n",
    "            dataset = process_view_hierarchy(view_hierarchy1, view_hierarchy2, dataset, False)\n",
    "            negative_samples_counter += 1\n",
    "            if negative_samples_counter >= negative_samples_threshold:\n",
    "                break\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset = []\n",
    "for trace_path in sorted(glob.glob(TRACES_PATH)):\n",
    "    process_trace(trace_path, dataset)\n",
    "\n",
    "dataset = add_negative_samples(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2609.6000000000004"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_positive_samples = len(dataset)\n",
    "negative_samples_threshold = 0.1 * total_positive_samples\n",
    "negative_samples_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "for row in dataset:\n",
    "    targets.append(re.sub('[%s]' % re.escape(string.punctuation), '', row[-1].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_words =  198026\n"
     ]
    }
   ],
   "source": [
    "# We create a custom standardization function to lowercase the text and \n",
    "# remove punctuation.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  lowercase = tf.strings.regex_replace(lowercase, '\\s', '')\n",
    "  return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "# Define the number of words in a sequence.\n",
    "sequence_length = 1\n",
    "\n",
    "# Use the text vectorization layer to normalize, split, and map strings to\n",
    "# integers. Set output_sequence_length length to pad all samples to same length.\n",
    "vectorize_layer = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "all_words = []\n",
    "for row in dataset:\n",
    "    for word in row:\n",
    "        all_words.append(str(word))\n",
    "unique_words = set(all_words)\n",
    "print('unique_words = ',len(unique_words))\n",
    "vectorize_layer.adapt(list(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '1', '0', '10', '000', '00', '11', '100', '2', '12', '20', '15', '5', '4', '3', 'signup', '21', '14', '13']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "177303"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the created vocabulary for reference.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])\n",
    "len(inverse_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15728  and  26096\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "c = 0\n",
    "t = 0\n",
    "for target in targets:\n",
    "    t += 1\n",
    "    if target in inverse_vocab:\n",
    "        c += 1\n",
    "        y_true.append(inverse_vocab.index(target))\n",
    "    else:\n",
    "        y_true.append(-1)\n",
    "print(c, ' and ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "text_vector_ds = text_ds.map(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    64 151389 114991 151389 122689 151389    296 151403 114993 151389\n",
      " 122690 151389    296 151403    217 151389  93014 151389    296 151389\n",
      " 148299 151404  58968 151404  51663 151404  54072 151389    296 151389\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298   4946 151389  34600 151389  61949 151389  61973 151389\n",
      "  46082 151389 100269 151389  46083 151389 100270 151389  46084 151389\n",
      " 100271 151389    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    217] => ['settings', 'androidwidgettextview', 'fancylist', 'androidwidgettextview', 'displaychapterslistusingcardviewwidget', 'androidwidgettextview', 'none', 'androidwidgetcheckbox', 'fancydetails', 'androidwidgettextview', 'displaychapterdetailsusingcardviewwidget', 'androidwidgettextview', 'none', 'androidwidgetcheckbox', 'language', 'androidwidgettextview', 'languageusedtodisplayapplicationdata', 'androidwidgettextview', 'none', 'androidwidgettextview', 'atrás', 'androidwidgetbutton', 'saltar', 'androidwidgetbutton', 'siguiente', 'androidwidgetbutton', 'settingsactivity', 'androidwidgettextview', 'none', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'supportdevelopment', 'androidwidgettextview', 'unabletoconnecttobillingservices', 'androidwidgettextview', 'removeadvertisinginthisapp', 'androidwidgettextview', 'removeadbannersandinterstitialadsinthisapplicationandenjoythecontent', 'androidwidgettextview', 'supportappdevelopmentsmall', 'androidwidgettextview', 'ifyouenjoythisapplicationyoucansupportusbybuyingthissmallpack', 'androidwidgettextview', 'supportappdevelopmentmedium', 'androidwidgettextview', 'ifyouenjoythisapplicationyoucansupportusbybuyingthismediumpack', 'androidwidgettextview', 'supportappdevelopmentlarge', 'androidwidgettextview', 'ifyouenjoythisapplicationyoucansupportusbybuyingthislargepack', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'language']\n",
      "[ 68277 151389 128935 151389  70835 151389 111724 151389  79001 151389\n",
      "  60579 151389  59993 151389  67383 151389  93910 151389  59994 151389\n",
      " 138176 151389 105256 151389 122711 151389 106412 151389 106411 151389\n",
      "   9669 151389     64 151389   4946 151389    235 151389    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298  90797 151389    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298   9669] => ['pocketphysics', 'androidwidgettextview', 'constantcircularmotion', 'androidwidgettextview', 'periodfrequencyangularvelocitycentripetalaccelerationcentripetalforce', 'androidwidgettextview', 'force', 'androidwidgettextview', 'newtonslawsweightforcenormalforcefriction', 'androidwidgettextview', 'rigidbody', 'androidwidgettextview', 'rotarymotionangulardisplacementangularvelocityangularaccelerationuniformlyvariablemotionmomentofinertiamomentofforcemomentofmomentumprincipleofconservationofmomentum', 'androidwidgettextview', 'powerworkenergy', 'androidwidgettextview', 'kineticenergypotentialenergywork', 'androidwidgettextview', 'rotarymotion', 'androidwidgettextview', 'centerofthemassangularpositionangularvelocitymomentofinertia', 'androidwidgettextview', 'harmonicmotion', 'androidwidgettextview', 'displacementangularfrequencyvelocityacceleration', 'androidwidgettextview', 'gravity', 'androidwidgettextview', 'gravityforcepotentialenergykepplerslaws', 'androidwidgettextview', 'chapters', 'androidwidgettextview', 'settings', 'androidwidgettextview', 'supportdevelopment', 'androidwidgettextview', 'about', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'linearmotion', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'chapters']\n",
      "[ 24437 151493    296 151508   6852 151436  52343 151436 105967 151493\n",
      " 103584 151493  35953 151493    796 151493  85247 151493 137923 151493\n",
      "      2 151493    296 151493     36 151436     23 151436    173 151436\n",
      "     47 151436     94 151436    168 151436    224 151436    310 151436\n",
      "    459 151436    449 151436   2702 151436   2685 151436    443 151436\n",
      "    214 151436    427 151436    295 151436    292 151436    635 151436\n",
      "    207 151436    615 151436    374 151436    570 151436    364 151436\n",
      "   1767 151436    265 151436   1705 151436    551 151436    551 151436\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298 103609 151493  89510\n",
      " 151493   1218 151493     89 151493  35788 151493    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    427] => ['wordguessgame', 'androidsupportv7widgetao', 'none', 'androidsupportv7viewmenuactionmenuitemview', 'newgame', 'androidsupportv7widgetr', 'showresult', 'androidsupportv7widgetr', 'guessthewordusingthehintbelow', 'androidsupportv7widgetao', 'hintलडाका', 'androidsupportv7widgetao', 'truuet', 'androidsupportv7widgetao', 'answer', 'androidsupportv7widgetao', 'melanoma', 'androidsupportv7widgetao', 'chancesleft', 'androidsupportv7widgetao', '1', 'androidsupportv7widgetao', 'none', 'androidsupportv7widgetao', 'next', 'androidsupportv7widgetr', 'a', 'androidsupportv7widgetr', 'b', 'androidsupportv7widgetr', 'c', 'androidsupportv7widgetr', 'd', 'androidsupportv7widgetr', 'e', 'androidsupportv7widgetr', 'f', 'androidsupportv7widgetr', 'g', 'androidsupportv7widgetr', 'h', 'androidsupportv7widgetr', 'i', 'androidsupportv7widgetr', 'j', 'androidsupportv7widgetr', 'k', 'androidsupportv7widgetr', 'l', 'androidsupportv7widgetr', 'm', 'androidsupportv7widgetr', 'n', 'androidsupportv7widgetr', 'o', 'androidsupportv7widgetr', 'p', 'androidsupportv7widgetr', 'q', 'androidsupportv7widgetr', 'r', 'androidsupportv7widgetr', 's', 'androidsupportv7widgetr', 't', 'androidsupportv7widgetr', 'u', 'androidsupportv7widgetr', 'v', 'androidsupportv7widgetr', 'w', 'androidsupportv7widgetr', 'x', 'androidsupportv7widgetr', 'y', 'androidsupportv7widgetr', 'z', 'androidsupportv7widgetr', 'z', 'androidsupportv7widgetr', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'hindienglishdictionarypoweredbyhinkhojcom', 'androidsupportv7widgetao', 'logintosaveyourwordsontheserver', 'androidsupportv7widgetao', 'loginwith', 'androidsupportv7widgetao', 'or', 'androidsupportv7widgetao', 'trywithoutlogin', 'androidsupportv7widgetao', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'n']\n",
      "[  3039 151389    454 151389   1430 151389    125 151389 112324 151389\n",
      "  61388 151389  51039 151389 146549 151389  24206 151389    228 151389\n",
      "    426 151389    199 151389     64 151389     26 151389    296 151389\n",
      "    296 151389  84346 151389    296 151389    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298   3039 151389    454 151389   1430 151389\n",
      " 143164 151389 143120 151389    125 151389 112324 151389  61388 151389\n",
      "  51039 151389 146549 151389  24206 151389    228 151389    426 151389\n",
      "    199 151389    296 151389    296 151389  84346 151389    296 151389\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298   1430] => ['dev', 'androidwidgettextview', 'home', 'androidwidgettextview', 'bookaflight', 'androidwidgettextview', 'checkin', 'androidwidgettextview', 'flightstatusschedules', 'androidwidgettextview', 'reservationticket', 'androidwidgettextview', 'skypass', 'androidwidgettextview', 'baggageinformation', 'androidwidgettextview', 'worldwideairports', 'androidwidgettextview', 'contactus', 'androidwidgettextview', 'news', 'androidwidgettextview', 'termsandconditions', 'androidwidgettextview', 'settings', 'androidwidgettextview', 'login', 'androidwidgettextview', 'none', 'androidwidgettextview', 'none', 'androidwidgettextview', 'mileageavailableforuse', 'androidwidgettextview', 'none', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'dev', 'androidwidgettextview', 'home', 'androidwidgettextview', 'bookaflight', 'androidwidgettextview', 'bookdomesticflightkorea', 'androidwidgettextview', 'bookinternationalflight', 'androidwidgettextview', 'checkin', 'androidwidgettextview', 'flightstatusschedules', 'androidwidgettextview', 'reservationticket', 'androidwidgettextview', 'skypass', 'androidwidgettextview', 'baggageinformation', 'androidwidgettextview', 'worldwideairports', 'androidwidgettextview', 'contactus', 'androidwidgettextview', 'news', 'androidwidgettextview', 'termsandconditions', 'androidwidgettextview', 'none', 'androidwidgettextview', 'none', 'androidwidgettextview', 'mileageavailableforuse', 'androidwidgettextview', 'none', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'bookaflight']\n",
      "[170088 151428 164328 151428 160473 151428 169617 151428 164135 151428\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298   1376 151389    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298    298    298    298    298\n",
      "    298    298    298    298    298    298 170088] => ['1monthgraph', 'androidsupportv7widgety', '3monthgraph', 'androidsupportv7widgety', '6monthgraph', 'androidsupportv7widgety', '1yeargraph', 'androidsupportv7widgety', '3yeargraph', 'androidsupportv7widgety', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'currency', 'androidwidgettextview', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', 'na', '1monthgraph']\n"
     ]
    }
   ],
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "sequences = np.squeeze(sequences)\n",
    "\n",
    "for seq in sequences[:5]:\n",
    "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_dataset(sequences, inverse_vocab):\n",
    "    num_ns = len(inverse_vocab)\n",
    "    labels = []\n",
    "    input_data = []\n",
    "    for input_instance in sequences:\n",
    "        y = input_instance[-1:]\n",
    "        labels.append(y)\n",
    "        input_data.append(input_instance[:-1])\n",
    "    categorized_labels = tf.keras.utils.to_categorical(labels, num_ns)\n",
    "    return tf.data.Dataset.from_tensor_slices((input_data, categorized_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(sequences, test_size=TEST_SIZE)\n",
    "train, val = train_test_split(sequences, test_size=VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = map_to_dataset(train, inverse_vocab).batch(BATCH_SIZE)\n",
    "val = map_to_dataset(val, inverse_vocab).batch(BATCH_SIZE)\n",
    "test = map_to_dataset(test, inverse_vocab).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  1/235 [..............................] - ETA: 0s - loss: 12.0856 - accuracy: 0.0000e+00WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "235/235 [==============================] - 238s 1s/step - loss: 12.0856 - accuracy: 0.1621 - val_loss: 12.0856 - val_accuracy: 0.1625\n",
      "Epoch 2/500\n",
      "235/235 [==============================] - 243s 1s/step - loss: 12.0671 - accuracy: 0.1646 - val_loss: 11.9233 - val_accuracy: 0.1625\n",
      "Epoch 3/500\n",
      "235/235 [==============================] - 243s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 4/500\n",
      "235/235 [==============================] - 245s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 5/500\n",
      "235/235 [==============================] - 243s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 6/500\n",
      "235/235 [==============================] - 245s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 7/500\n",
      "235/235 [==============================] - 241s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 8/500\n",
      "235/235 [==============================] - 245s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 9/500\n",
      "235/235 [==============================] - 241s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 10/500\n",
      "235/235 [==============================] - 244s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 11/500\n",
      "235/235 [==============================] - 242s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 12/500\n",
      "235/235 [==============================] - 241s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 13/500\n",
      "235/235 [==============================] - 242s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 14/500\n",
      "235/235 [==============================] - 244s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 15/500\n",
      "235/235 [==============================] - 243s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 16/500\n",
      "235/235 [==============================] - 240s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 17/500\n",
      "235/235 [==============================] - 244s 1s/step - loss: 11.9211 - accuracy: 0.1646 - val_loss: 11.9232 - val_accuracy: 0.1625\n",
      "Epoch 18/500\n",
      "202/235 [========================>.....] - ETA: 32s - loss: 11.9211 - accuracy: 0.1645"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(MAX_TOKEN*4, )),\n",
    "    tf.keras.layers.Embedding(len(inverse_vocab), 10, input_length=1),\n",
    "    tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dense(len(inverse_vocab), activation='softmax')\n",
    "])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train, validation_data=val, epochs=500, callbacks=[tensorboard_callback], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
